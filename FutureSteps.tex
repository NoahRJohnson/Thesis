\chapter{Future Steps}

\section{Field Test scenario}

\subsection{Results}

Used virtual\_joystick node with other differential\_drive control nodes to drive rover around a parking lot. Recorded data into a ROS bag file, which is ...

here is route fitted on top of satellite image of that parking lot:

\section{ROS Navigation Stack}

\subsection{ros\_controller}
\begin{figure}[h]
	\caption{ROS control overview \cite{fig_ros_control}}
	\includegraphics[]{gazebo_ros_control}
	\label{fig:ros_controller}
\end{figure}



\subsection{GPS Waypoints}
GPS markers form a linearized path
travel in a straight line from one GPS node to another
%https://www.google.com/maps/d/edit?mid=1wKgTvF7i7Xdpi42cw1ffAOrGDVw&ll=27.38460862376806%2C-82.56151826455687&z=17


\section{Project Limitations}
how this project is limited

robot is heavy enough that acceleration must be considered in the diff drive kinematics

approximation of skid steering as diff drive. wheel slippage makes those kinematic equations untenable.

refine covariance matrices, especially for odometry estimate

introduction of a camera, but attaching a webcam directly to the chassis of the robot would be troublesome to work with, sense there would be no shock absorption and the video frames would wobble.

Integration of GPS data into position estimate causes discrete jumps, may make it unsuitable for use in the navigation stack. Solution: ditch GPS, use range data from ultrasonic sensor with amcl


\section{Conclusion}
