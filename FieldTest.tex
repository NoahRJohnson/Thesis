\chapter{Field Test}

In order to test the rover's ability to localize itself, a simple field test was conducted in a parking lot. Inspiration for this experiment comes from Moore and Stouch \cite{robot_localization_paper}.
% An attempt was made to replicate the results in paper

\section{Experiment Design}

The rover was initially placed in a parking lot oriented westwards. It was then driven in a loop around the lot using the virtual\_joystick node, described in section \ref{sectionJoystick}. See Figure \ref{fig:roverPath} for two representations of the path taken. Figure \ref{figRouteMemory} displays the path actually traversed, while Figure \ref{figRouteGPS} is constructed from the phone's GPS readings. Note that despite Figure \ref{figRouteGPS}, at no point did the rover go onto the grass. The rover was driven so that its initial and ending position and orientation were roughly equal. Total collection time was five and a half minutes.

While the rover moved, raw sensor data streaming in from the Arduino and smartphone was recorded and saved into a ROS bag file.  Later, the \textit{rosbag} utility was used to repeatedly simulate the recorded sensor messages, while the EKF was run in different configurations. The rover's state was first computed from raw wheel odometry, then from wheel odometry fused with IMU data, and lastly from wheel odometry, IMU data, and GPS fixes all together. Refer to Table \ref{tab:configs} for a review of which state variables each sensor affects.

\section{Results}

% laptop had no problem computing using the filter. No memory spikes either. Very computationally efficient! laptop is enough for localization - is it enough for navigation?

During each filter computation, a state estimate was produced at 30 Hz in a local frame, and that output was then transformed into the global UTM frame, where position is given as latitude and longitude. These gps coordinates were plotted using the handy GPS Visualizer tool \cite{gps_visualizer} to generate the plots in  Figure \ref{fig:ekfOutputs}.

Figure \ref{figRouteOdom} shows the estimated path when fusing only the wheel encoder odometry. The initial trajectory heading north and the subsequent turn westward is tracked reasonably well, but the second turn rotates too far and throws the rest of the estimate off.

Figure \ref{figRouteOdomImu} shows the path generated when fusing wheel odometry with IMU data. In this case the shape of the path is much closer to truth, though the initial northern trajectory is under-estimated.


% were impacted negatively during the field test by external magnetic fields other than the earth's. The field test itself was carried out in a parking lot filled with cars, some of which were running. Large metal bodies with flowing current cause large magnetic fields. 


Lastly, Figure \ref{figRouteOdomImuGps} shows the result of fusing both prior sensors with GPS fixes. This plot looks much like the raw gps plot in Figure \ref{figRouteGPS}, however upon close inspection one can see jagged jumps in position. These jumps are instantaneous and actually lead to a discontinuous position estimate, though the visualizing tool connects every point. They are caused by the filter instantaneously adjusting the position estimate based on incoming gps fixes. The filter gives some weight to the current estimate, so the new adjusted position lies in between the position reported by the gps fix and the current estimate. Due to the frequent gps fixes and slow velocity of the rover, the estimated path never varies too far from the raw gps path.

\begin{table}[h]
	\caption {Errors for Different Sensor Fusions \cite{robot_localization_paper}} \label{tab:errors} 
	\begin{center}
		\begin{tabular}{|c|c|c|} \hline
			\textbf{Sensors Fused} & \textbf{Loop Closure Error x,y (m)} & \textbf{Std. Dev. x,y (m)} \\ \hline
			Wheel Encoders & -88.37, -43.10 & 45.64, 126.36 \\ \hline
			Encoders + IMU & -12.90, -11.89 & 52.80,  52.02 \\ \hline
			Encoders + IMU + GPS & -0.97, -0.50 & 4.68,  4.56 \\ \hline
		\end{tabular}
	\end{center}
\end{table}

Table \ref{tab:errors} shows the position error between the rover's start and end positions for each filter configuration. Because the rover's local frame has its origin at the start point, this error is simply the last state estimate produced by the filter. The standard deviation for each dimension is also reported, giving an idea of the filter's confidence in its location. Note that the position errors are negative because the filter considers the end point to be in the -X and -Y direction of the rover's starting orientation. Recall that according to ROS convention, this translates to being behind and to the right of the starting position. This makes sense because the rover started facing west.

\begin{figure}[p] 
	\caption{
		The rover's path.
	}
	\label{fig:roverPath}
	\begin{subfigure}{\textwidth}
		\centering
		\includegraphics[height=0.45\textheight]{testRun/route_from_memory}
		\caption{Path Manually Mapped}
		\label{figRouteMemory}
	\end{subfigure}
	\begin{subfigure}{\textwidth}
		\centering
		\includegraphics[height=0.4\textheight]{testRun/raw_gps_data}
		\caption{Path According to Phone's GPS}
		\label{figRouteGPS}
	\end{subfigure}
	
\end{figure}

\begin{figure}[p] 
	\caption{
		Filter Outputs For Different Sensor Fusions
	}
	\label{fig:ekfOutputs}
	\begin{subfigure}{\textwidth}
		\centering
		\includegraphics[height=0.4\textheight]{testRun/ekf_output_odom}
		\caption{Raw Wheel Odometry}
		\label{figRouteOdom}
	\end{subfigure}
	\begin{subfigure}{\textwidth}
		\centering
		\includegraphics[height=0.4\textheight]{testRun/ekf_output_odom_imu}
		\caption{Wheel Odometry + IMU}
		\label{figRouteOdomImu}
	\end{subfigure}
	
\end{figure}

\begin{figure}[p] \ContinuedFloat
	\begin{subfigure}{\textwidth}
		\centering
		\includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{testRun/ekf_output_odom_imu_gps}
		\caption{Wheel Odometry + IMU + GPS}
		\label{figRouteOdomImuGps}
	\end{subfigure}
\end{figure}